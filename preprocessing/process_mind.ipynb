{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414007c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, pandas as pd\n",
    "\n",
    "NEWS_COLS = [\"news_id\",\"category\",\"subcategory\",\"title\",\"abstract\",\"url\",\"title_entities\",\"abstract_entities\"]\n",
    "news = pd.read_csv(\"../mind_data/MINDsmall_train/news.tsv\", sep=\"\\t\", header=None, names=NEWS_COLS)\n",
    "news = news.drop_duplicates(\"news_id\").set_index(\"news_id\")\n",
    "\n",
    "def _clean(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = re.sub(r\"[\\r\\n]+\", \" \", s).strip()\n",
    "    return s[:2000]  # safety cap\n",
    "\n",
    "news[\"text\"] = (news[\"title\"].map(_clean) + \" \" + news[\"abstract\"].map(_clean)).str.strip()\n",
    "\n",
    "def _parse_entities(s):\n",
    "    if not isinstance(s, str) or not s.strip(): return []\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        return json.loads(s.replace(\"'\", '\"'))  # fallback for rare dumps\n",
    "\n",
    "news[\"title_entities\"]    = news[\"title_entities\"].map(_parse_entities)\n",
    "news[\"abstract_entities\"] = news[\"abstract_entities\"].map(_parse_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7361922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'lifestyle', 'subcategory': 'lifestyleroyals', 'title': 'The Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By', 'abstract': \"Shop the notebooks, jackets, and more that the royals can't live without.\", 'url': 'https://assets.msn.com/labs/mind/AAGH0ET.html', 'title_entities': [{'Label': 'Prince Philip, Duke of Edinburgh', 'Type': 'P', 'WikidataId': 'Q80976', 'Confidence': 1.0, 'OccurrenceOffsets': [48], 'SurfaceForms': ['Prince Philip']}, {'Label': 'Charles, Prince of Wales', 'Type': 'P', 'WikidataId': 'Q43274', 'Confidence': 1.0, 'OccurrenceOffsets': [28], 'SurfaceForms': ['Prince Charles']}, {'Label': 'Elizabeth II', 'Type': 'P', 'WikidataId': 'Q9682', 'Confidence': 0.97, 'OccurrenceOffsets': [11], 'SurfaceForms': ['Queen Elizabeth']}], 'abstract_entities': [], 'text': \"The Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By Shop the notebooks, jackets, and more that the royals can't live without.\"}\n"
     ]
    }
   ],
   "source": [
    "#print the  first row\n",
    "print(news.iloc[0].to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def read_behaviors(path):\n",
    "    BEH_COLS = [\"imp_id\",\"user_id\",\"time\",\"history\",\"impressions\"]\n",
    "    beh = pd.read_csv(path, sep=\"\\t\", header=None, names=BEH_COLS)\n",
    "    def ph(x): return [] if pd.isna(x) or not x else x.split()\n",
    "    def pi(x):\n",
    "        out=[]\n",
    "        for tok in x.split():\n",
    "            if \"-\" in tok:\n",
    "                nid, lab = tok.split(\"-\")\n",
    "                out.append((nid, int(lab)))\n",
    "            else:  # test split may have no labels\n",
    "                out.append((tok, None))\n",
    "        return out\n",
    "    beh[\"hist_list\"] = beh[\"history\"].map(ph)\n",
    "    beh[\"impr_list\"] = beh[\"impressions\"].map(pi)\n",
    "    return beh\n",
    "\n",
    "train_beh = read_behaviors(\"../mind_data/MINDsmall_train/behaviors.tsv\")\n",
    "#dev_beh   = read_behaviors(\"../mind_data/MINDsmall_dev/behaviors.tsv\")\n",
    "\n",
    "# indices\n",
    "all_news_ids = set(news.index.tolist())\n",
    "def collect_ids(beh):\n",
    "    nids=set(); uids=set()\n",
    "    for h in beh[\"hist_list\"]:\n",
    "        nids.update(h)\n",
    "    for im in beh[\"impr_list\"]:\n",
    "        nids.update([nid for nid,_ in im])\n",
    "    uids.update(beh[\"user_id\"].tolist())\n",
    "    return uids, nids\n",
    "\n",
    "uids_tr, nids_tr = collect_ids(train_beh)\n",
    "#uids_dev, nids_dev = collect_ids(dev_beh)\n",
    "\n",
    "# Keep only news that appear in news.tsv (some may not)\n",
    "#used_news = (nids_tr | nids_dev) & all_news_ids\n",
    "\n",
    "news2idx = {nid:i for i,nid in enumerate(sorted(used_news))}\n",
    "#user2idx = {uid:i for i,uid in enumerate(sorted(uids_tr | uids_dev))}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
